@: Usage
#: Time/Space complexity

*** Concerns for Data Structure
    - null allowance, synchronization, sort

*** Recursion
    - what are argus? Have return type? final terminal condition?

* String
  - Immutable
  - StringBuilder and StringBuffer is mutable object. StringBuffer is synchronized while StringBuilder is not, which makes StringBuilder faster and recommended whenever possible.

* Hash Table
  - n keys -> Hashcode (to integers) -> Compression Function (to N buckets)
  - load factor = n/N should stay low to avoid collision on duplicate keys. If not , time complexity could be O(n) instead of O(1).
  - If load factor is too big, resize hashtable and change compression func

  JAVA
  - HashMap: null allowed, unsynchronized
             Map m = Collections.synchronizedMap(new HashMap(...));
  - HashTable: null not allowed, synchronized

* Array

* List JAVA
  - Allow null
  - fail fast for both LinkedList and ArrayList, Vector

* LinkedList JAVA
  # Insert/Delete O(1), find nth O(n)
  - Doubly-linked list implementation of the List and Deque interfaces.
  - null allowed, not synchronized
  - List list = Collections.synchronizedList(new LinkedList(...)); // synchronized

* ArrayList JAVA
  # Insert/Delete O(n), find nth O(1)
  # The add operation runs in amortized constant time, that is, adding n elements requires O(n) time.
  - Resizable-array implementation of the List interface. Default is 10.

* Vector Java
  - Synchronized. Recommend ArrayList than Vector in thread-safe env.

* Stack
  # push, pop, top take O(1) time
  @ reverse e.g. parenthesis matching

  JAVA
  - Stack: empty, peek, pop, push, search
  - Implemented by Vector
  - Prefer to use Dequeue(LinkedList or ArrayDeque)

* Queue
  - A collection for holding elements prior to processing.
  - it has head and tail,
  - Null not allowed for all Queue related class and interface
  @ waiting line, buffer for I/O, keyboard stroke.

  JAVA
  - Interface Queue: add, poll ...
  - Interface BlockingQueue: a Queue that add wait for non-empty to retrieve and for space to add. Thread safe.
  - LinkedBlockingQueue is unbounded and has higher throughput.
  - ArrayBlockingQueue is bounded and has to give capacity. Less throughput but less variablility in performance.
  - Interface Dequeue("double ended queue"). Can be used as queue or stack. Implementation includes ArrayDeque and LinkedList

* Priority Queue
  - Entries consist of key and value. Order is defined on keys. null not allowed.
  - Implemented by Binary Heap.
  # Min O(1), Insert O(logn), RemoveMin O(logn), Construct O(n)
  @ Used as "event queue", key is the time event take place, value is description.

  JAVA
  - PriorityQueue (implements Queue: add, poll, peek...)
  - not synchronized, use PriorityBlockingQueue for synchronization

------------------ Tree -------------------
* Tree
  - balance
  - insert, delete, find, min, max, predecessor, succssor

* Heap
  - complete binary tree(bottom from left to right, diff from full binary tree)

* Binary Search Tree
  - unbalanced
  # inorder, preorder, postorder traversal O(n) (http://www.geeksforgeeks.org/tree-traversals-inorder-preorder-and-postorder/)
  # O(logn) for all ops in balanced tree. Proportional to depth of deepest node in unbalanced tree.
  - sucessor, predessor (https://discuss.leetcode.com/topic/25076/share-my-java-recursive-solution)

* Treap (Balanced BST, easy to implement than RBT)
  - Each node has n.key (BST key) and n.value(min Heap). key and value are both distinct. First construct by key then rotate by value
  - insert(rotate) example http://www.geeksforgeeks.org/treap-set-2-implementation-of-search-insert-and-delete/
  # all ops take O(logn), e.g. insert: add red based on BST find, then rotate
  @ set operation, wireless networking, memory allocation

* Red Black Tree (Balanced BST)
  - balanced binary search tree
  - root and leaf are black. child of red is black. every path has same # of black. height <= 2Log2(n+1)
  # all ops take O(logn), e.g. insert: add red based on BST find, then recolor or rotate

* B Tree
  - A b tree node is usually as large as a disk page, the number of disk access is at most the height of the b tree
  # all ops take O(logn), space O(n)
  @ used in external memory, database and file system

* Trie (Radix Tree)
  @ for prefix search purpose, replace hashtable. e.g. get all strings starts with 'pre'
  @ predictive text, autocomplete, spell checking, prefix tree

* Segment Tree
  - Sum of given range, also can be used for string
  - Complete binary tree. In array, parent index i, left child 2i+1, right child 2i-1, root index 0
  - (http://www.geeksforgeeks.org/segment-tree-set-1-sum-of-given-range/)
  # get sum O(logn), update O(logn)
  @ sum of given range, like number or string

* Binary Indexed Tree
  @ Sum of prefix
  # get sum O(logn), update O(logn)

------------------ Searching --------------

* Binary Search

* DFS
  - search on directed, weighted, cycled graph.
  - https://www.geeksforgeeks.org/depth-first-traversal-for-a-graph/
  # O(V+E)
  @ detect cycle. find maze. Topological sort.

* BFS
  - search on directed, weighted, cycled graph.
  - https://www.geeksforgeeks.org/breadth-first-traversal-for-a-graph/
  # O(V+E)
  @ minimum spanning tree, dijkstra single source shortest path

------------------ Sorting ----------------

* Insertion Sort
  - stable, in-place
  # O(n^2), proportional to inversions

* Selection Sort
  - stable, in-place
  # O(n^2)

* Heap Sort
  - (https://java2blog.com/heap-sort-in-java/)
  - (https://www.geeksforgeeks.org/heap-sort/)
  - heapify -> build heap from bottom i=(size-1)/2 -> swap and heapify
  - not stable, in-place, good for array not for linkedlist
  # O(nlogn)
  @ excellent for arrays

* Merge Sort
  - divide and conquer, postorder sort
    sort(arr,l,m); sort(arr,m+1,r);merge(arr,l,m,r);
  - stable, not in-place
  - # O(nlogn)
  @ prefer for linked list

* Quick Sort
  - divide and conquer, preorder sort
    - pick pivot and partition
  - stable or not in-place
  - # O(nlogn)
  @ find kth smallest key in list, if list is sorted, arr[k-1] should be the kth smallest. Partition and recursion based on index k-1. O(n) average time.

* Counting Sort (small range, int)
  - sort value within a small range, create array(largest_int), map each into array and then concatenate all together.
  - http://www.javacodex.com/Sorting/Bucket-Sort
  # O(n)
  @ small range int, letters

* Bucket Sort (small range, int/float)
  - sort value within a small range, create fixed number array (if int, same as Counting Sort), map each into array and insertion sort for each bucket, then concatenate all together.
  - sort float example(https://www.geeksforgeeks.org/bucket-sort-2/)
  - consider Counting Sort first
  # O(n)

* Radix Sort (large range)
  - counting sort from last digit to first digit
  - https://www.geeksforgeeks.org/radix-sort/
  # O(n)

** Topological Sort
  - Only for Directed Acyclic Graph(DAG). Ordering of its vertices along a horizontal line so all directed edges go from left to right.
  - post order traversal and put vertex to stack after visit all its children
  - https://www.geeksforgeeks.org/topological-sorting/
  # O(V+E)
  @ Schedule jobs from the given dependency among jobs. Determine order of compilation tasks.

------------------ Graph ------------------

* Union Find
  - assume no self cycle
  - interate edges, find root for each vertex in an edge and compare, if same it has cycle else union. Use rank(level) for each vertex to compress path.
  - (https://www.geeksforgeeks.org/union-find-algorithm-set-2-union-by-rank/)
  @ detect cycle in undirected graph

* Detect cycle
  - undirected: Union Find, assume no self-loops
  - directed: DFS and keep recursion stack to check back edge

* Connected Component
  - undirected: interate vertices and call DFS/BFS
  -

* Strongly Connected Component
  - maximal set of vertices and for each pair u and v, it has path u -> v and v -> u
  - DFS on all vertices and put into stack, then change direcion of graph, then pop from stack and do DFS and print strongly connected component
  - (https://www.geeksforgeeks.org/strongly-connected-components/)
  @ social network

* Kruskal’s Minimum Spanning Tree （undirected graph)
  - sort edges and iterate, for each iteration if no circle, add edge until # of edges reach to V-1. Greedy algorithm.
  - use Union find to detect cycle
  - undirected graph only, for directed graph it may failed to detect cycle
  - (https://www.geeksforgeeks.org/greedy-algorithms-set-2-kruskals-minimum-spanning-tree-mst/)
  # O(ElogE) or O(ElogV)

* Prim’s Minimum Spanning Tree (undirected graph)
  - Two disjoint subsets of vertices must be connected to make a Spanning Tree. And must be connected with the minimum weight edge to make it MST.
  - Matain 2 sets, for each time pick up the reachable minimum weight edge from not MST set until V-1
  - undirected graph only, for directed graph not every node is reachable
  # O(V^2) for adjacency matrix. O(E log V) for adjacency list

* Dijsktra's Single Source Shortest Path (directed and undirected)
  - Maintain path set and array of distance from each vertex to source. For each interation, add the smallest distance vertext to path set and update distance array until V-1. Similar to Prim's MST
  - work for both directed graph and undirected graph
  - for negative weight edges, need to use Bellman-Ford algo, or turn negative edge into base 0.
  # O(V^2) for adjacency matrix, O(E log V) for adjacency list with binary heap

* Least Common Ancestor
  - post traversal, find the first node includes i, j
  - find path from root to i, j. Then interate from lowest(i,j) level to root

* Range Minimum Query

------------------ Other ------------------
* Dynamic Programming
  - recursion + memorization + guessing, remmeber and reuse solutions to subproblems (acyclic)
  - time = #subproblems * (time/subproblem) -> O(1)


















